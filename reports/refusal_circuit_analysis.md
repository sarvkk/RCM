# Refusal Circuit Analysis Report

**Generated:** 2026-01-12 01:44:56
**Author:** SaycuredAI Research

---

## Executive Summary

This report presents the results of mechanistic interpretability experiments
aimed at identifying the neural circuit responsible for refusal behavior in
large language models.

### Key Findings

- Analyzed **5** models
- Average refusal direction separation: **0.93σ**

---

## Methodology

### Activation Patching

We use activation patching to identify which model components are causally
responsible for refusal behavior. The procedure:

1. Run model on a refusal-triggering prompt, cache activations
2. Run model on a structurally similar compliant prompt, cache activations
3. Re-run the refusal prompt, but patch in activations from the compliant run
4. Measure how much the patching changes the refusal behavior

Components that, when patched, cause large behavior changes are identified as
part of the "refusal circuit."

### Refusal Direction

We compute a "refusal direction" in activation space by:

1. Collecting activations for refusal prompts and compliant prompts
2. Computing the difference between mean activations (refusal - compliant)
3. Normalizing to get a unit direction vector

This direction can be used for steering experiments.

### Steering Validation

To validate that we found the refusal mechanism, we:

1. **Force refusal**: Add the refusal direction to harmless prompts
2. **Suppress refusal**: Subtract the refusal direction from harmful prompts

If behavior changes as expected, this proves causal identification.

---

## Results

### Per-Model Results

| Model | Type | Separation | Probe Acc. | Force Refusal | Suppress Refusal |
|-------|------|------------|------------|---------------|------------------|
| pythia-70m | base | 0.457σ | 86.7% | 3.3% | 0.0% |
| pythia-160m | base | 0.548σ | 80.0% | 0.0% | 0.0% |
| gpt2 | base | 1.486σ | 100.0% | 0.0% | 0.0% |
| pythia-410m | base | 1.635σ | 83.3% | 0.0% | 5.6% |
| gpt2-medium | base | 0.545σ | 100.0% | 0.0% | 0.0% |

### Critical Components

The following components were identified as critical for refusal behavior:

**Most frequently critical layers:**

- Layer 0: appeared in 5 models
- Layer 1: appeared in 5 models
- Layer 2: appeared in 5 models
- Layer 3: appeared in 5 models
- Layer 4: appeared in 5 models

---

## Discussion

### Interpretation

The results suggest that refusal behavior in language models is:

1. **Localized**: Specific layers and attention heads are disproportionately responsible
2. **Steerable**: We can manipulate refusal by intervening on the identified direction
3. **Consistent**: Similar circuits appear across different model sizes

### Implications for AI Safety

Understanding refusal circuits helps us:

- Build more robust safety mechanisms
- Understand how alignment techniques affect model internals
- Develop better interpretability tools

### Limitations

- Base models (without safety training) show weak refusal signals
- Steering effects may not generalize to all prompt types
- Analysis limited by computational resources to smaller models

---

## Reproducibility

To reproduce these results:

```bash
# Install dependencies
pip install -r requirements.txt

# Run experiments
python experiments/batch_runner.py --config experiments/config.yaml

# Generate reports
python -m src.reports.generator --input results/ --output reports/
```

---

*Report generated by SaycuredAI Refusal Circuit Analysis Framework*